<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>羊羊博客</title>
  
  <subtitle>黑白世界，有你看不到的色彩！</subtitle>
  <link href="https://yoursite.com/atom.xml" rel="self"/>
  
  <link href="https://yoursite.com/"/>
  <updated>2020-08-15T07:23:41.427Z</updated>
  <id>https://yoursite.com/</id>
  
  <author>
    <name>郑坪杨</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>test1</title>
    <link href="https://yoursite.com/2020/08/15/test1/"/>
    <id>https://yoursite.com/2020/08/15/test1/</id>
    <published>2020-08-14T23:03:20.000Z</published>
    <updated>2020-08-15T07:23:41.427Z</updated>
    
    <content type="html"><![CDATA[<p>此文档用于测试！</p><p>opencv</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;此文档用于测试！&lt;/p&gt;
&lt;p&gt;opencv&lt;/p&gt;
</summary>
      
    
    
    
    
    <category term="opencv" scheme="https://yoursite.com/tags/opencv/"/>
    
  </entry>
  
  <entry>
    <title>test2</title>
    <link href="https://yoursite.com/2020/08/15/test2/"/>
    <id>https://yoursite.com/2020/08/15/test2/</id>
    <published>2020-08-14T23:03:20.000Z</published>
    <updated>2020-08-15T02:50:33.546Z</updated>
    
    <content type="html"><![CDATA[<h1 id="爬虫笔记"><a href="#爬虫笔记" class="headerlink" title="爬虫笔记"></a>爬虫笔记</h1><h2 id="第一章-网络请求"><a href="#第一章-网络请求" class="headerlink" title="第一章 网络请求"></a>第一章 网络请求</h2><h3 id="一-HTTP协议和chrome抓包工具"><a href="#一-HTTP协议和chrome抓包工具" class="headerlink" title="一. HTTP协议和chrome抓包工具"></a>一. HTTP协议和chrome抓包工具</h3><h3 id="什么是http和https协议："><a href="#什么是http和https协议：" class="headerlink" title="什么是http和https协议："></a>什么是http和https协议：</h3><p>​    HTTP协议：全称是HwperTextTransfer Protocol，中文意思是超文本传输协议，是一种发布和接收HTML页面的方法。服务器端口号是80端口。<br>​            HTTPS协议；是HTTP协议的加密版本，在HTTP下加入了SSL层，颜务器端口号是443端口。</p><h3 id="在浏览器中发送一个http请求的过程："><a href="#在浏览器中发送一个http请求的过程：" class="headerlink" title="在浏览器中发送一个http请求的过程："></a>在浏览器中发送一个http请求的过程：</h3><p>​            1.当用户在浏览器的地址栏中输入一个URL并按回车键之后，浏览器会向HTTP服务器发送HTTP请求。HTTP请求主要分为“Get”和“Post”两种方法。<br>​            2.当我们在浏览器输入URL http:/<a href="http://www.baidu.com的时候,浏览器发送一个request请求去获取htp//www.baidu.com%E7%9A%84htm%E6%96%87%E4%BB%B6%EF%BC%8C%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8A%8AResponse%E6%96%87%E4%BB%B6%E5%AF%B9%E8%B1%A1%E5%8F%91%E9%80%81%E5%9B%9E%E7%BB%99%E6%B5%8F%E8%A7%88%E5%99%A8%E3%80%82">www.baidu.com的时候，浏览器发送一个Request请求去获取htp://www.baidu.com的htm文件，服务器把Response文件对象发送回给浏览器。</a><br>​            3.浏览器分析Response中的HTML，发现其中引用了很多其他文件，比如mages文件，CSS文件，JS文件。刻货器会自动再次发送Request去获取图片，CSS文件，或者JS文件。<br>​            4.当所有的文件都下载成功后，网页会根据HTML语法结构，完整的显示出来了。</p><h3 id="url详解"><a href="#url详解" class="headerlink" title="url详解"></a>url详解</h3><p>URL是Unifora Resource Locator的简写，统一资源定位符。一个URL由以下几部分组成：</p><p>​            <strong>schene://host:port/path/？query-string-xxx#anchor</strong></p><p>scheme：代表的是访问的协议，一般为http或者https以及代p等。<br>        host：主机名，域名，比如ww.baidu.com。<br>        port：端口号。当你访问一个网站的时候，浏览器默认使用80端口。<br>        path：查找路径。比如：ww.jianshu.com/trending/now，后面的trending/now 就是path。<br>        query-string：查询字符串，比如：wwr.baidu.con/s7we-python，后面的wd-oython 就是查询字符串。<br>        anchor：锚点，后台一般不用管，前端用来做页面定位的。<br>        在浏览器中请求一个url，浏览器会对这个url进行一个编码。除英文字母，数字和部分符号外，其他的全部使用百分号+十六进制码值进行编码。</p><h3 id="常用的请求方法"><a href="#常用的请求方法" class="headerlink" title="常用的请求方法"></a>常用的请求方法</h3><p>在Http协议中，定义了八种请求方法。这里介绍两种常用的请求方法，分别是set请求和post请求。<br>        1.get请求：一般情况下，只从服务器获取数据下来，并不会对服务器资源产生任何影响的时候会使用get 请求。<br>        2.post 请求：向服务器发送数据（登录）、上传文件等，会对服务器资源产生影响的时候会使用post请求。<br>以上是在网站开发中常用的两种方法。并且一般情况下都会遵循使用的原则。但是有的网站和服务器为了做反爬虫机制，也经常会不按常理出牌，有可能一个应该使用aet方法的请求就一定要改成post请求，这个要视情况而定。</p><h3 id="请求头常见参数"><a href="#请求头常见参数" class="headerlink" title="请求头常见参数"></a>请求头常见参数</h3><p>在http协议中，向服务器发送一个请求，数据分为三部分，第一个是把数据放在ul中，第二个是把数据放在boay中（在post请求中），第三个就是把数据放在head中。这里介绍在网络虫中经常会用到的一些请求头参数：<br>        1.user-Agent：浏览器名称。这个在网络爬虫中经常会被使用到。请求一个网页的时候，服务器通过这个参数就可以知道这个请求是由哪种刻览器发送的。如果我们是通过爬虫发送请求，那么我们user-Agent 就是aythcn，这对于那些有反爬虫机制的网站来说，可以轻易的判断你这个请求是爬虫。因此我们要经常设置这个植为一些浏览器的值，来伪装我们的爬虫。<br>        2.Referer；表明当前这个请求是从哪个ur1过来的。这个一般也可以用来做反爬虫技术。如果不是从指定页面过来的，那么就不做相关的响应。<br>        3.cookie:http 协议是无状态的。也就是同一个人发送了两次请求，服务器没有能力知道这两个请求是否来自同一个人。因此这时候就用cookie来做标识。一般如果想要做登录后才能访问的网站，那么就需要发送cookie信息了。</p><h3 id="常见响应状态码"><a href="#常见响应状态码" class="headerlink" title="常见响应状态码"></a>常见响应状态码</h3><p>1.200：请求正常，服务器正常的返回数据。<br>        2.301：永久重定向。比如在访问ww.jingdong.com的时候会重定向到ww.jc.com。<br>        3.302：临时重定向。比如在访问一个需要登录的页面的时候，而此时没有登录，那么就会重定向到登录页面。<br>        4.400：请求的ur1在服务器上找不到。换句话说就是请求ur1错误。<br>        5.403：服务器拒绝访问，权限不够。<br>        6.500：服务器内部错误。可能是服务器出现bug了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;爬虫笔记&quot;&gt;&lt;a href=&quot;#爬虫笔记&quot; class=&quot;headerlink&quot; title=&quot;爬虫笔记&quot;&gt;&lt;/a&gt;爬虫笔记&lt;/h1&gt;&lt;h2 id=&quot;第一章-网络请求&quot;&gt;&lt;a href=&quot;#第一章-网络请求&quot; class=&quot;headerlink&quot; title=&quot;第</summary>
      
    
    
    
    
    <category term="爬虫" scheme="https://yoursite.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
</feed>
